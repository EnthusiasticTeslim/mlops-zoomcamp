{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/Users/gbemidebe/Documents/GitHub/mlops-zoomcamp/02-experiment-tracking/examples/case02/mlruns/1', creation_time=1716753193765, experiment_id='1', last_update_time=1716753193765, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"nyc-taxi-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists\n"
     ]
    }
   ],
   "source": [
    "# get data: check if directory exist. if yes, skip else create new one\n",
    "import os, wget\n",
    "data_directory = 'data/'\n",
    "if os.path.exists(data_directory):\n",
    "    print(\"Directory exists\")\n",
    "else:\n",
    "    os.mkdir(data_directory)\n",
    "    print(\"Directory does not exist and created new one\")\n",
    "\n",
    "# set directory\n",
    "os.chdir(f'./{data_directory}')\n",
    "# Download files\n",
    "remote_desktop = False\n",
    "if remote_desktop:\n",
    "    if not os.path.exists('green_tripdata_2021-01.parquet'):\n",
    "        !wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet\n",
    "    if not os.path.exists('green_tripdata_2021-02.parquet'):\n",
    "        !wget https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet\n",
    "else:\n",
    "    if not os.path.exists('green_tripdata_2021-01.parquet'):\n",
    "        wget.download('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet')\n",
    "    if not os.path.exists('green_tripdata_2021-02.parquet'):\n",
    "        wget.download('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet')\n",
    "os.chdir(f'../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('./data/green_tripdata_2021-01.parquet').iloc[:2000]\n",
    "df_val = read_dataframe('./data/green_tripdata_2021-02.parquet').iloc[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical = ['PU_DO'] \n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory exists\n"
     ]
    }
   ],
   "source": [
    "# save the dictionary vectorizer\n",
    "import pickle\n",
    "if os.path.exists(\"saved_models\"):\n",
    "    print(\"Directory exists\")\n",
    "else:\n",
    "    os.mkdir(\"saved_models\")\n",
    "    print(\"Directory does not exist and created new one\")\n",
    "    \n",
    "with open(\"saved_models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/26 15:35:08 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/05/26 15:35:10 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/gbemidebe/miniconda3/envs/exp-tracking-env/lib/python3.9/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\"\n",
      "2024/05/26 15:35:10 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/05/26 15:35:12 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "2024/05/26 15:35:14 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "/Users/gbemidebe/miniconda3/envs/exp-tracking-env/lib/python3.9/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "for model_class in (RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, LinearSVR):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.log_param(\"train-data-path\", \"./data/green_tripdata_2021-01.csv\")\n",
    "        mlflow.log_param(\"valid-data-path\", \"./data/green_tripdata_2021-02.csv\")\n",
    "        mlflow.log_artifact(\"saved_models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        mlmodel = model_class()\n",
    "        mlmodel.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = mlmodel.predict(X_val)\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gbemidebe/miniconda3/envs/exp-tracking-env/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:35:15] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/05/26 15:35:17 WARNING mlflow.xgboost: Failed to infer model signature: could not sample data to infer model signature: please ensure that autologging is enabled before constructing the dataset.\n",
      "2024/05/26 15:35:17 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/gbemidebe/miniconda3/envs/exp-tracking-env/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [15:35:17] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\"\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    train = xgb.DMatrix(X_train, label=y_train)\n",
    "    valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # culled from the instructor solution\n",
    "    best_params = {\n",
    "        'learning_rate': 0.09585355369315604,\n",
    "        'max_depth': 30,\n",
    "        'min_child_weight': 1.060597050922164,\n",
    "        'objective': 'reg:linear',\n",
    "        'reg_alpha': 0.018060244040060163,\n",
    "        'reg_lambda': 0.011658731377413597,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    booster = xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=train,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(valid, 'validation')],\n",
    "        early_stopping_rounds=50, verbose_eval=False\n",
    "    )\n",
    "\n",
    "    y_pred = booster.predict(valid)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    with open(\"saved_models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
